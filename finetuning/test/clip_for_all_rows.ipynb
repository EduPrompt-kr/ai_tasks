{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "461169a5-ee53-4fce-afae-317779d7364a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved results to /Users/fatihwolf/Downloads/images 2/image_similarity_scores.xlsx\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from PIL import Image\n",
    "import torch\n",
    "import clip\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# üìÅ Set your image folder path\n",
    "image_folder = \"/Users/fatihwolf/Downloads/images 2\"\n",
    "\n",
    "# üß† Load CLIP model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/16\", device=device)\n",
    "\n",
    "def get_clip_embedding(image_path):\n",
    "    image = preprocess(Image.open(image_path)).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        return model.encode_image(image).cpu().numpy()[0]\n",
    "\n",
    "# üìä Data collection\n",
    "results = []\n",
    "\n",
    "# Loop through image pairs\n",
    "for i in range(1, 270):  # row_1 to row_269\n",
    "    teacher_path = os.path.join(image_folder, f\"row_{i}_teacher.png\")\n",
    "    student_path = os.path.join(image_folder, f\"row_{i}_student.png\")\n",
    "\n",
    "    if not os.path.exists(teacher_path) or not os.path.exists(student_path):\n",
    "        print(f\"‚ö†Ô∏è Skipping row {i}: Missing file(s)\")\n",
    "        continue\n",
    "\n",
    "    # Load and preprocess images\n",
    "    img1 = cv2.imread(teacher_path)\n",
    "    img2 = cv2.imread(student_path)\n",
    "    img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "    img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Resize to match\n",
    "    height = min(img1_gray.shape[0], img2_gray.shape[0])\n",
    "    width = min(img1_gray.shape[1], img2_gray.shape[1])\n",
    "    img1_resized = cv2.resize(img1_gray, (width, height))\n",
    "    img2_resized = cv2.resize(img2_gray, (width, height))\n",
    "\n",
    "    # Pixel similarity\n",
    "    mse_val = np.mean((img1_resized - img2_resized) ** 2)\n",
    "    ssim_val = ssim(img1_resized, img2_resized)\n",
    "\n",
    "    # CLIP semantic similarity\n",
    "    embedding1 = get_clip_embedding(teacher_path)\n",
    "    embedding2 = get_clip_embedding(student_path)\n",
    "    cosine_similarity = np.dot(embedding1, embedding2) / (np.linalg.norm(embedding1) * np.linalg.norm(embedding2))\n",
    "    scaled_clip_score = ((cosine_similarity - 0.6) / 0.4) * 100  # Scale to 0‚Äì100\n",
    "\n",
    "    # Append results\n",
    "    results.append({\n",
    "        \"Row\": i,\n",
    "        \"MSE\": round(mse_val, 2),\n",
    "        \"SSIM\": round(ssim_val, 4),\n",
    "        \"CLIP Cosine\": round(cosine_similarity, 4),\n",
    "        \"Scaled CLIP Score (0‚Äì100)\": round(scaled_clip_score, 2)\n",
    "    })\n",
    "\n",
    "# üìù Save to Excel\n",
    "df = pd.DataFrame(results)\n",
    "output_excel = os.path.join(image_folder, \"image_similarity_scores.xlsx\")\n",
    "df.to_excel(output_excel, index=False)\n",
    "\n",
    "print(f\"‚úÖ Saved results to {output_excel}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fb9f193-2c61-4e95-ba6a-ae608a92001a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Merged Excel file saved at: /Users/fatihwolf/Downloads/merged_file_corrected_captions.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# üìÅ List your Excel file paths\n",
    "csv_files = [\n",
    "    \"/Users/fatihwolf/Downloads/formatted_rows_1_to_50.csv\",\n",
    "    \"/Users/fatihwolf/Downloads/formatted_rows_51_to_100.csv\",\n",
    "    \"/Users/fatihwolf/Downloads/formatted_rows_101_to_150.csv\",\n",
    "    \"/Users/fatihwolf/Downloads/formatted_rows_151_to_200.csv\",\n",
    "    \"/Users/fatihwolf/Downloads/formatted_rows_201_to_250.csv\"\n",
    "]\n",
    "\n",
    "# üìä Load and concatenate all CSVs\n",
    "all_dataframes = [pd.read_csv(file) for file in csv_files]\n",
    "merged_df = pd.concat(all_dataframes, ignore_index=True)\n",
    "\n",
    "# üíæ Save to a new Excel file\n",
    "output_path = \"/Users/fatihwolf/Downloads/merged_file_corrected_captions.csv\"\n",
    "merged_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"‚úÖ Merged Excel file saved at: {output_path}\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb5197cb-e25c-4aac-82bb-a771d0387693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Scoring complete! Results saved to caption_similarity_scores.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Load caption similarity model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Define weights per category\n",
    "weights = {\n",
    "    \"main_objects\": 0.55,\n",
    "    \"main_object_attributes\": 0.05,\n",
    "    \"location\": 0.15,\n",
    "    \"action\": 0.15,\n",
    "    \"surroundings\": 0.05,\n",
    "    \"background\": 0.05\n",
    "}\n",
    "\n",
    "# --- Parse captions into structured dict ---\n",
    "def parse_caption(raw_caption: str):\n",
    "    categories = {\n",
    "        \"main_objects\": r\"Main Object[s]?:\\s*(.*?)(?=(Attributes|location|action|surroundings|background|$))\",\n",
    "        \"main_object_attributes\": r\"Attributes:\\s*(.*?)(?=(location|action|surroundings|background|$))\",\n",
    "        \"location\": r\"location:\\s*(.*?)(?=(action|surroundings|background|$))\",\n",
    "        \"action\": r\"action:\\s*(.*?)(?=(surroundings|background|$))\",\n",
    "        \"surroundings\": r\"surroundings:\\s*(.*?)(?=(background|$))\",\n",
    "        \"background\": r\"background:\\s*(.*)\"\n",
    "    }\n",
    "    parsed = {}\n",
    "    for key, pattern in categories.items():\n",
    "        match = re.search(pattern, raw_caption, re.IGNORECASE)\n",
    "        if match:\n",
    "            items = [i.strip() for i in match.group(1).split(\",\") if i.strip()]\n",
    "            parsed[key] = items\n",
    "        else:\n",
    "            parsed[key] = []\n",
    "    return parsed\n",
    "\n",
    "# --- Similarity calculator ---\n",
    "def compute_similarity(list1, list2):\n",
    "    if not list1 or not list2:\n",
    "        return 0.0\n",
    "    text1 = ', '.join(list1)\n",
    "    text2 = ', '.join(list2)\n",
    "    embedding1 = model.encode(text1, convert_to_tensor=True)\n",
    "    embedding2 = model.encode(text2, convert_to_tensor=True)\n",
    "    return float(util.cos_sim(embedding1, embedding2).item())\n",
    "\n",
    "# --- Compute weighted total similarity ---\n",
    "def score_pair(teacher_caption, student_caption):\n",
    "    total_score = 0.0\n",
    "    details = {}\n",
    "    for key in weights:\n",
    "        t_val = teacher_caption.get(key, [])\n",
    "        s_val = student_caption.get(key, [])\n",
    "        score = compute_similarity(t_val, s_val)\n",
    "        weighted_score = score * weights[key]\n",
    "        total_score += weighted_score\n",
    "        details[key + \"_sim\"] = round(score, 3)\n",
    "        details[key + \"_weighted\"] = round(weighted_score, 3)\n",
    "    details[\"final_score\"] = round(total_score, 3)\n",
    "    return details\n",
    "\n",
    "# --- Load CSV ---\n",
    "df = pd.read_csv(\"/Users/fatihwolf/Downloads/filtered_test_50.csv\")  # Replace with your file path\n",
    "\n",
    "# --- Apply parsing and scoring ---\n",
    "results = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    student_text = str(row[\"Student\"])\n",
    "    teacher_text = str(row[\"Teacher\"])\n",
    "    parsed_student = parse_caption(student_text)\n",
    "    parsed_teacher = parse_caption(teacher_text)\n",
    "    similarity_scores = score_pair(parsed_teacher, parsed_student)\n",
    "    \n",
    "    result_row = {\n",
    "        \"Row\": row[\"Row\"],\n",
    "        \"Student\": student_text,\n",
    "        \"Teacher\": teacher_text,\n",
    "        **similarity_scores\n",
    "    }\n",
    "    results.append(result_row)\n",
    "\n",
    "# --- Save to CSV ---\n",
    "output_df = pd.DataFrame(results)\n",
    "output_df.to_csv(\"/Users/fatihwolf/Downloads/caption_scores_test_gpt_fixed.csv\", index=False)\n",
    "print(\"‚úÖ Scoring complete! Results saved to caption_similarity_scores.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "530a1d8e-ba18-4ea9-aa9a-1011b541a905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Scoring complete! Results saved to caption_similarity_scores.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Load caption similarity model\n",
    "model = SentenceTransformer('sentence-transformers/all-roberta-large-v1')\n",
    "\n",
    "# Define weights per category\n",
    "weights = {\n",
    "    \"main_objects\": 0.55,\n",
    "    \"main_object_attributes\": 0.05,\n",
    "    \"location\": 0.15,\n",
    "    \"action\": 0.15,\n",
    "    \"surroundings\": 0.05,\n",
    "    \"background\": 0.05\n",
    "}\n",
    "\n",
    "# --- Parse captions into structured dict ---\n",
    "def parse_caption(raw_caption: str):\n",
    "    categories = {\n",
    "        \"main_objects\": r\"Main Object[s]?:\\s*(.*?)(?=(Attributes|location|action|surroundings|background|$))\",\n",
    "        \"main_object_attributes\": r\"Attributes:\\s*(.*?)(?=(location|action|surroundings|background|$))\",\n",
    "        \"location\": r\"location:\\s*(.*?)(?=(action|surroundings|background|$))\",\n",
    "        \"action\": r\"action:\\s*(.*?)(?=(surroundings|background|$))\",\n",
    "        \"surroundings\": r\"surroundings:\\s*(.*?)(?=(background|$))\",\n",
    "        \"background\": r\"background:\\s*(.*)\"\n",
    "    }\n",
    "    parsed = {}\n",
    "    for key, pattern in categories.items():\n",
    "        match = re.search(pattern, raw_caption, re.IGNORECASE)\n",
    "        if match:\n",
    "            items = [i.strip() for i in match.group(1).split(\",\") if i.strip()]\n",
    "            parsed[key] = items\n",
    "        else:\n",
    "            parsed[key] = []\n",
    "    return parsed\n",
    "\n",
    "# --- Similarity calculator ---\n",
    "def compute_similarity(list1, list2):\n",
    "    if not list1 or not list2:\n",
    "        return 0.0\n",
    "    text1 = ', '.join(list1)\n",
    "    text2 = ', '.join(list2)\n",
    "    embedding1 = model.encode(text1, convert_to_tensor=True)\n",
    "    embedding2 = model.encode(text2, convert_to_tensor=True)\n",
    "    return float(util.cos_sim(embedding1, embedding2).item())\n",
    "\n",
    "# --- Compute weighted total similarity ---\n",
    "def score_pair(teacher_caption, student_caption):\n",
    "    total_score = 0.0\n",
    "    details = {}\n",
    "    for key in weights:\n",
    "        t_val = teacher_caption.get(key, [])\n",
    "        s_val = student_caption.get(key, [])\n",
    "        score = compute_similarity(t_val, s_val)\n",
    "        weighted_score = score * weights[key]\n",
    "        total_score += weighted_score\n",
    "        details[key + \"_sim\"] = round(score, 3)\n",
    "        details[key + \"_weighted\"] = round(weighted_score, 3)\n",
    "    details[\"final_score\"] = round(total_score, 3)\n",
    "    return details\n",
    "\n",
    "# --- Load CSV ---\n",
    "df = pd.read_csv(\"/Users/fatihwolf/Downloads/merged_file_corrected_captions.csv\")  # Replace with your file path\n",
    "\n",
    "# --- Apply parsing and scoring ---\n",
    "results = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    student_text = str(row[\"Student\"])\n",
    "    teacher_text = str(row[\"Teacher\"])\n",
    "    parsed_student = parse_caption(student_text)\n",
    "    parsed_teacher = parse_caption(teacher_text)\n",
    "    similarity_scores = score_pair(parsed_teacher, parsed_student)\n",
    "    \n",
    "    result_row = {\n",
    "        \"Row\": row[\"Row\"],\n",
    "        \"Student\": student_text,\n",
    "        \"Teacher\": teacher_text,\n",
    "        **similarity_scores\n",
    "    }\n",
    "    results.append(result_row)\n",
    "\n",
    "# --- Save to CSV ---\n",
    "output_df = pd.DataFrame(results)\n",
    "output_df.to_csv(\"/Users/fatihwolf/Downloads/caption_sim_scores_ours_roberta.csv\", index=False)\n",
    "print(\"‚úÖ Scoring complete! Results saved to caption_similarity_scores.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b547d86-5acf-4958-a070-f4fc3cfda416",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
