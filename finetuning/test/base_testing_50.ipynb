{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f012b838",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d1c3d00ad6c4b71abaed9c38466a300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Row 1 done.\n",
      "✅ Row 2 done.\n",
      "✅ Row 3 done.\n",
      "✅ Row 4 done.\n",
      "✅ Row 5 done.\n",
      "✅ Row 6 done.\n",
      "✅ Row 7 done.\n",
      "✅ Row 8 done.\n",
      "✅ Row 9 done.\n",
      "✅ Row 10 done.\n",
      "✅ Row 11 done.\n",
      "✅ Row 12 done.\n",
      "✅ Row 13 done.\n",
      "✅ Row 14 done.\n",
      "✅ Row 15 done.\n",
      "✅ Row 16 done.\n",
      "✅ Row 17 done.\n",
      "✅ Row 18 done.\n",
      "✅ Row 19 done.\n",
      "✅ Row 20 done.\n",
      "✅ Row 21 done.\n",
      "✅ Row 22 done.\n",
      "✅ Row 23 done.\n",
      "✅ Row 24 done.\n",
      "✅ Row 25 done.\n",
      "✅ Row 26 done.\n",
      "✅ Row 27 done.\n",
      "✅ Row 28 done.\n",
      "✅ Row 29 done.\n",
      "✅ Row 30 done.\n",
      "✅ Row 31 done.\n",
      "✅ Row 32 done.\n",
      "✅ Row 33 done.\n",
      "✅ Row 34 done.\n",
      "✅ Row 35 done.\n",
      "✅ Row 36 done.\n",
      "✅ Row 37 done.\n",
      "✅ Row 38 done.\n",
      "✅ Row 39 done.\n",
      "✅ Row 40 done.\n",
      "✅ Row 41 done.\n",
      "✅ Row 42 done.\n",
      "✅ Row 43 done.\n",
      "✅ Row 44 done.\n",
      "✅ Row 45 done.\n",
      "✅ Row 46 done.\n",
      "✅ Row 47 done.\n",
      "✅ Row 48 done.\n",
      "✅ Row 49 done.\n",
      "✅ Row 50 done.\n",
      "\n",
      "📄 Saved results to /workspace/50set/caption_results_base.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, MllamaForConditionalGeneration\n",
    "\n",
    "# ---- CONFIG ----\n",
    "base_model_id = \"unsloth/Llama-3.2-11B-Vision-Instruct\"\n",
    "folder = Path(\"/workspace/50set\")\n",
    "output_csv = folder / \"caption_results_base.csv\"\n",
    "\n",
    "# ---- LOAD BASE MODEL ONLY ----\n",
    "model = MllamaForConditionalGeneration.from_pretrained(\n",
    "    base_model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "# ---- LOAD PROCESSOR ----\n",
    "processor = AutoProcessor.from_pretrained(base_model_id)\n",
    "\n",
    "# ---- INSTRUCTION ----\n",
    "instruction = (\n",
    "    \"You are a vision-language assistant. Describe an image using exactly six categories in a single line:\\n\\n\"\n",
    "    \"main_objects: ... main_object_attributes: ... location: ... action: ... surroundings: ... background: ...\\n\\n\"\n",
    "    \"Format rules:\\n\"\n",
    "    \"- Each category must start with its name, followed by a colon and a space\\n\"\n",
    "    \"- Use detailed, specific descriptions\\n\"\n",
    "    \"- Separate categories with a comma and a space\\n\"\n",
    "    \"- If a category is unclear, write: [category name]: none\\n\"\n",
    "    \"- Do NOT include commentary, line breaks, or extra text\\n\\n\"\n",
    "    \"Example:\\n\"\n",
    "    \"main_objects: rabbit main_object_attributes: brown fur, fluffy tail, big ears, happy expression location: meadow action: none surroundings: butterflies, flowers, green grass background: foliage, sunlight\"\n",
    ")\n",
    "\n",
    "# ---- HELPER FUNCTION ----\n",
    "def generate_caption(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    messages = [{\"role\": \"user\", \"content\": [{\"type\": \"image\"}, {\"type\": \"text\", \"text\": instruction}]}]\n",
    "    input_text = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "    inputs = processor(image, input_text, add_special_tokens=False, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_new_tokens=200)\n",
    "    return processor.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# ---- PROCESS BATCH ----\n",
    "results = []\n",
    "for i in range(1, 51):\n",
    "    index = str(i).zfill(3)\n",
    "    student_img = folder / f\"{index}_student.png\"\n",
    "    teacher_img = folder / f\"{index}_teacher.png\"\n",
    "\n",
    "    if student_img.exists() and teacher_img.exists():\n",
    "        student_caption = generate_caption(student_img)\n",
    "        teacher_caption = generate_caption(teacher_img)\n",
    "        results.append({\"Row\": i, \"Student\": student_caption, \"Teacher\": teacher_caption})\n",
    "        print(f\"✅ Row {i} done.\")\n",
    "    else:\n",
    "        print(f\"⚠️ Missing pair for row {i}.\")\n",
    "\n",
    "# ---- SAVE TO CSV ----\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(output_csv, index=False)\n",
    "print(f\"\\n📄 Saved results to {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03da9568",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
